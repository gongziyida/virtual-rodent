{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893c3121-9eac-4734-914a-2859b34893c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb909f48-34c0-4ff0-a8de-e4f75cfd1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from virtual_rodent.environment import MAPPER\n",
    "from virtual_rodent import VISION_DIM, PROPRI_DIM, ACTION_DIM\n",
    "from virtual_rodent.network.vision_enc import ResNet18Enc\n",
    "from virtual_rodent.network.propri_enc import MLPEnc\n",
    "import virtual_rodent.network.Merel2019 as Merel2019\n",
    "from virtual_rodent.utils import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c01084-3262-4763-91be-b0adbc22f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_enc = ResNet18Enc()\n",
    "vision_emb_dim = vision_enc.get_emb_dim(VISION_DIM)\n",
    "\n",
    "propri_emb_dim = 20 # propri_dim\n",
    "propri_enc = MLPEnc(PROPRI_DIM[0], propri_emb_dim, hidden_dims=(50,))\n",
    "\n",
    "critic_in_dim = vision_emb_dim + propri_emb_dim\n",
    "critic = Merel2019.Critic(critic_in_dim)\n",
    "\n",
    "actor_in_dim = critic_in_dim + PROPRI_DIM[0] + critic.hidden_dim\n",
    "actor = Merel2019.Actor(actor_in_dim, ACTION_DIM, logit_scale=1)\n",
    "\n",
    "model = Merel2019.MerelModel(vision_enc, propri_enc, VISION_DIM, PROPRI_DIM, \n",
    "                             actor, critic, ACTION_DIM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20b3ab2-4ec6-49a8-a4c5-18a3c4ee1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load('./results/weights1000.pth', weights_only=True)\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "547ca63e-08f9-4090-8fd9-e115dda5c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'gaps'\n",
    "# env_name = 'maze'\n",
    "env, propri_attr = MAPPER[env_name](physics_dt=0.002, ctrl_dt=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85994640-69ea-403d-a62b-60841b942408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from virtual_rodent.simulation import get_vision, get_propri\n",
    "def simulate(env, model, propri_attr, max_step, device, reset=True, time_step=None,\n",
    "             ext_cam=(0,), ext_cam_size=(200, 200)):\n",
    "    \"\"\"Simulate until stop criteron is met\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    returns = dict(vision=[], propri=[], action=[], reward=[], log_prob=[], value=[], touch=[])\n",
    "    returns.update(dict({f'cam{i}': [] for i in ext_cam}))\n",
    "    \n",
    "    if reset:\n",
    "        time_step = env.reset()\n",
    "        if hasattr(model, 'reset_rnn'):\n",
    "            model.reset_rnn()\n",
    "    else:\n",
    "        if time_step is None:\n",
    "            raise ValueError('`time_step` must be given if not reset.')\n",
    "\n",
    "    action_spec = env.action_spec()\n",
    "\n",
    "    for step in range(max_step):\n",
    "        if time_step.last():\n",
    "            break\n",
    "        # Get state, reward and discount\n",
    "        vision = torch.from_numpy(get_vision(time_step)).to(device)\n",
    "        propri = torch.from_numpy(get_propri(time_step, propri_attr)).to(device)\n",
    "\n",
    "        value, (action, log_prob, _) = model(vision=vision, propri=propri)\n",
    "\n",
    "        time_step = env.step(np.clip(action.detach().cpu().squeeze().numpy(), \n",
    "                                     action_spec.minimum, action_spec.maximum))\n",
    "\n",
    "        # Record state t, action t, reward t and done t+1; reward at start is 0\n",
    "        returns['vision'].append(vision)\n",
    "        returns['propri'].append(propri)\n",
    "        returns['action'].append(action)\n",
    "        returns['reward'].append(torch.tensor(time_step.reward))\n",
    "        returns['log_prob'].append(log_prob)\n",
    "        returns['value'].append(value)\n",
    "        for i in ext_cam:\n",
    "            cam = env.physics.render(camera_id=i, \n",
    "                    height=ext_cam_size[0], width=ext_cam_size[1])\n",
    "            returns[f'cam{i}'].append(cam)\n",
    "\n",
    "    end_time = time.time()\n",
    "    returns['time'] = end_time - start_time\n",
    "    returns['T'] = step \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b199be0d-e9f9-451a-8f93-294440f0a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from virtual_rodent.visualization import video\n",
    "# from virtual_rodent.simulation import simulate\n",
    "ext_cam = (0,)\n",
    "save_dir = './'\n",
    "ext_cam_size = (200, 200)\n",
    "with torch.no_grad():\n",
    "    ret = simulate(env, model, propri_attr, max_step=100, device=torch.device('cpu'), ext_cam=ext_cam)\n",
    "for i in ext_cam:\n",
    "    anim = video(ret[f'cam{i}'])\n",
    "    fname = f'demo_{env_name}_cam{i}.gif'\n",
    "    anim.save(os.path.join(save_dir, fname), writer='pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b6eb2-13f7-4df8-8613-53d5afdbe648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
